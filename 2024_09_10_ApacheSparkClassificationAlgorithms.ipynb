{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ4th3_9rmEg",
        "outputId": "2e76d79d-f2d7-43a7-ec12-61a13f9073d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=4a857cae66610e981f044184d8ae7f4751b43bbbce650534b6bcb6a8df705478\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naïve Bayes Classifier dự đoán Angelina Jolie có bệnh tim không\n",
        "import random\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.mllib.classification import NaiveBayes\n",
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"GNBClassifier\").getOrCreate()\n",
        "\n",
        "# Function to generate random LabeledPoint data (replace with real heart disease data)\n",
        "def generate_data(num_samples=50, num_features=13):  # Adjust num_features as needed\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        label = random.choice([0.0, 1.0])\n",
        "        features = [random.uniform(1.0, 10.0) for _ in range(num_features)]  # Adjust range based on actual data\n",
        "        data.append(LabeledPoint(label, Vectors.dense(features)))\n",
        "    return data\n",
        "\n",
        "# Generate data for training (replace with real data for actual use)\n",
        "data = generate_data(50, num_features=13)\n",
        "\n",
        "# Create RDD\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "\n",
        "# Split the data into training (60%) and test (40%)\n",
        "training, test = rdd.randomSplit([0.6, 0.4], seed=42)\n",
        "\n",
        "# Train a Gaussian Naive Bayes model\n",
        "model = NaiveBayes.train(training, 1.0)\n",
        "\n",
        "# Make prediction and test accuracy\n",
        "predictions_and_labels = test.map(lambda p: (model.predict(p.features), p.label))\n",
        "predictions_and_labels = predictions_and_labels.collect()\n",
        "\n",
        "# Model accuracy\n",
        "correct = sum(1 for x in predictions_and_labels if x[0] == x[1])\n",
        "accuracy = correct / len(predictions_and_labels)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Predict heart disease\n",
        "# Data for Angelina Jolie\n",
        "new_data = [\n",
        "    [53, 1, 0, 140, 203, 1, 0, 155, 1, 3.1, 0, 0, 3]  # Age, sex, chest pain type, blood pressure, cholesterol, fasting blood sugar, ECG results, heart rate, exercise angina, oldpeak, ST slope, vessels colored, thalassemia\n",
        "]\n",
        "\n",
        "# Name corresponding to new data\n",
        "names = [\"Angelina Jolie\"]\n",
        "\n",
        "# Convert new data to RDD of Vectors (no labels needed here)\n",
        "new_rdd = spark.sparkContext.parallelize(new_data).map(lambda x: Vectors.dense(x))\n",
        "\n",
        "# Make predictions\n",
        "try:\n",
        "    predictions = new_rdd.map(lambda features: model.predict(features))\n",
        "    predictions_result = predictions.collect()\n",
        "\n",
        "    # Print predictions with names\n",
        "    for name, features, prediction in zip(names, new_data, predictions_result):\n",
        "        print(f\"{name} (Features: {features}) - Prediction: {'Heart Disease' if prediction == 1.0 else 'No Heart Disease'}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxVGu1_mUxtv",
        "outputId": "b8d631ff-8c78-47bd-e4b1-ecac399c67c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 35.29%\n",
            "Angelina Jolie (Features: [53, 1, 0, 140, 203, 1, 0, 155, 1, 3.1, 0, 0, 3]) - Prediction: No Heart Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K Nearest Neighbor Classifier dự đoán Angelina Jolie có bệnh tim không\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "import numpy as np\n",
        "from pyspark.sql.types import StructType, StructField, FloatType\n",
        "\n",
        "# Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"KNNClassifier\").getOrCreate()\n",
        "\n",
        "# Hàm sinh dữ liệu giả lập với 13 đặc trưng\n",
        "def generate_data(num_samples):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        label = float(np.random.choice([0.0, 1.0]))  # Nhãn bệnh tim hoặc không bệnh tim\n",
        "        features = [float(np.random.uniform(1.0, 20.0)) for _ in range(13)]  # 13 đặc trưng\n",
        "        data.append((label, *features))\n",
        "    return data\n",
        "\n",
        "# Sinh 50 dòng dữ liệu\n",
        "data = generate_data(50)\n",
        "\n",
        "# Định nghĩa schema cho DataFrame với 13 đặc trưng\n",
        "schema = StructType([\n",
        "    StructField(\"label\", FloatType(), False),\n",
        "    *[StructField(f\"feature{i}\", FloatType(), False) for i in range(1, 14)]  # 13 đặc trưng\n",
        "])\n",
        "\n",
        "# Tạo DataFrame từ dữ liệu\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Chuyển đổi các đặc trưng thành vector\n",
        "assembler = VectorAssembler(inputCols=[f\"feature{i}\" for i in range(1, 14)], outputCol=\"features\")\n",
        "df_transformed = assembler.transform(df).select(\"label\", \"features\")\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "train_data, test_data = df_transformed.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Convert DataFrames to RDDs\n",
        "train_rdd = train_data.rdd.map(lambda row: (row.label, np.array(row.features.toArray())))\n",
        "test_rdd = test_data.rdd.map(lambda row: (row.label, np.array(row.features.toArray())))\n",
        "\n",
        "# Collect training data to the driver\n",
        "train_data_list = train_rdd.collect()\n",
        "\n",
        "# Định nghĩa hàm phân loại bằng KNN\n",
        "def knn_predict(test_point, train_data_list, k=3):\n",
        "    distances = [(label, np.linalg.norm(test_point - features)) for label, features in train_data_list]\n",
        "    nearest_neighbors = sorted(distances, key=lambda x: x[1])[:k]  # Lấy k hàng xóm gần nhất\n",
        "    labels = [label for label, _ in nearest_neighbors]\n",
        "    return max(set(labels), key=labels.count)  # Trả về nhãn phổ biến nhất\n",
        "\n",
        "# Dự đoán nhãn cho dữ liệu kiểm tra\n",
        "def predict_label(test_point):\n",
        "    return knn_predict(test_point[1], train_data_list)\n",
        "\n",
        "predictions = test_rdd.map(lambda test_point: (test_point[0], predict_label(test_point)))\n",
        "\n",
        "# Tính toán độ chính xác\n",
        "correct_predictions = predictions.filter(lambda x: x[0] == x[1]).count()\n",
        "total_predictions = predictions.count()\n",
        "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "print(f\"Độ chính xác của mô hình: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Dự đoán bệnh tim cho Angelina Jolie\n",
        "# Giả sử Angelina Jolie có 13 đặc trưng như sau\n",
        "angelina_jolie_features = np.array([53, 1, 0, 140, 203, 1, 0, 155, 1, 3.1, 0, 0, 3])\n",
        "\n",
        "# Dự đoán bệnh tim cho Angelina Jolie\n",
        "angelina_prediction = knn_predict(angelina_jolie_features, train_data_list)\n",
        "print(f\"Angelina Jolie - Prediction: {'Heart Disease' if angelina_prediction == 1.0 else 'No Heart Disease'}\")\n",
        "\n",
        "# Dừng Spark session\n",
        "spark.stop()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3FjW1iXgAkQ",
        "outputId": "73187289-921d-4028-80bb-0ceb523feeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Độ chính xác của mô hình: 58.33%\n",
            "Angelina Jolie - Prediction: No Heart Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extremely Randomized Trees dự đoán Angelina Jolie có bệnh tim không\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import numpy as np\n",
        "from pyspark.sql.types import StructType, StructField, FloatType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"ExtraTreesClassifier\").getOrCreate()\n",
        "\n",
        "# Hàm tạo dữ liệu ngẫu nhiên\n",
        "def generate_data(num_samples):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        label = float(np.random.choice([0.0, 1.0]))  # Nhãn bệnh tim hoặc không bệnh tim\n",
        "        features = [float(np.random.uniform(1.0, 20.0)) for _ in range(13)]  # 13 đặc trưng\n",
        "        data.append((label, *features))\n",
        "    return data\n",
        "\n",
        "# Sinh 50 dòng dữ liệu\n",
        "data = generate_data(50)\n",
        "\n",
        "# Định nghĩa schema cho DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"label\", FloatType(), False),\n",
        "    StructField(\"feature1\", FloatType(), False),\n",
        "    StructField(\"feature2\", FloatType(), False),\n",
        "    StructField(\"feature3\", FloatType(), False),\n",
        "    StructField(\"feature4\", FloatType(), False),\n",
        "    StructField(\"feature5\", FloatType(), False),\n",
        "    StructField(\"feature6\", FloatType(), False),\n",
        "    StructField(\"feature7\", FloatType(), False),\n",
        "    StructField(\"feature8\", FloatType(), False),\n",
        "    StructField(\"feature9\", FloatType(), False),\n",
        "    StructField(\"feature10\", FloatType(), False),\n",
        "    StructField(\"feature11\", FloatType(), False),\n",
        "    StructField(\"feature12\", FloatType(), False),\n",
        "    StructField(\"feature13\", FloatType(), False)\n",
        "])\n",
        "\n",
        "# Tạo DataFrame từ dữ liệu\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Chuyển đổi các cột đặc trưng thành một vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"feature{i}\" for i in range(1, 14)],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "df = assembler.transform(df)\n",
        "df = df.select(\"label\", \"features\")\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "(training_data, test_data) = df.randomSplit([0.6, 0.4])\n",
        "\n",
        "# Tạo mô hình RandomForestClassifier (Extra Trees là một biến thể của RandomForest)\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "model = rf.fit(training_data)\n",
        "\n",
        "# Dự đoán trên tập kiểm tra\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Dự đoán bệnh tim cho Angelina Jolie\n",
        "# Cần thay đổi thông tin cụ thể của Angelina Jolie thành 13 đặc trưng tương ứng\n",
        "angelina_jolie_features = np.array([53, 1, 0, 140, 203, 1, 0, 155, 1, 3.1, 0, 0, 3])\n",
        "\n",
        "# Chuyển đổi dữ liệu của Angelina Jolie thành DataFrame (với kiểu Vector cho cột 'features')\n",
        "def create_features_vector(features):\n",
        "    return Vectors.dense(features)\n",
        "\n",
        "# Chuyển dữ liệu của Angelina Jolie thành DataFrame\n",
        "angelina_df = spark.createDataFrame([(create_features_vector(angelina_jolie_features.tolist()),)], [\"features\"])\n",
        "\n",
        "# Dự đoán\n",
        "angelina_prediction = model.transform(angelina_df).select(\"prediction\").collect()[0][0]\n",
        "print(f\"Angelina Jolie - Prediction: {'Heart Disease' if angelina_prediction == 1.0 else 'No Heart Disease'}\")\n",
        "\n",
        "# Dừng Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xft2f3_AC_e",
        "outputId": "7d83446a-c037-46c6-c110-359436063cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 60.00%\n",
            "Angelina Jolie - Prediction: Heart Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network - Multi-Layer Perceptron dự đoán Angelina Jolie có bệnh tim không\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, FloatType\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.linalg import Vectors\n",
        "import numpy as np\n",
        "\n",
        "# Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"MLPClassifier\").getOrCreate()\n",
        "\n",
        "# Hàm tạo dữ liệu ngẫu nhiên\n",
        "def generate_data(num_samples):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        label = float(np.random.choice([0.0, 1.0]))  # Nhãn bệnh tim hoặc không bệnh tim\n",
        "        features = [float(np.random.uniform(1.0, 20.0)) for _ in range(13)]  # 13 đặc trưng\n",
        "        data.append((label, *features))\n",
        "    return data\n",
        "\n",
        "# Sinh 50 dòng dữ liệu\n",
        "data = generate_data(50)\n",
        "\n",
        "# Định nghĩa schema cho DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"label\", FloatType(), False),\n",
        "    *[StructField(f\"feature{i}\", FloatType(), False) for i in range(1, 14)]\n",
        "])\n",
        "\n",
        "# Tạo DataFrame từ dữ liệu\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Chuyển đổi các cột đặc trưng thành một vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"feature{i}\" for i in range(1, 14)],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "df = assembler.transform(df)\n",
        "df = df.select(\"label\", \"features\")\n",
        "\n",
        "# Định nghĩa cấu trúc mạng nơ-ron\n",
        "layers = [13, 8, 6, 2]  # 13 đặc trưng đầu vào, 8 nơ-ron lớp ẩn đầu tiên, 6 nơ-ron lớp ẩn thứ hai, 2 lớp đầu ra\n",
        "\n",
        "# Tạo mô hình MultiLayerPerceptronClassifier\n",
        "mlp = MultilayerPerceptronClassifier(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    maxIter=100,\n",
        "    layers=layers,\n",
        "    blockSize=128,\n",
        "    seed=1234\n",
        ")\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "(training_data, test_data) = df.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "model = mlp.fit(training_data)\n",
        "\n",
        "# Dự đoán trên tập kiểm tra\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Dự đoán bệnh tim cho Angelina Jolie\n",
        "# Cần thay đổi thông tin cụ thể của Angelina Jolie thành 13 đặc trưng tương ứng\n",
        "angelina_jolie_features = np.array([53, 1, 0, 140, 203, 1, 0, 155, 1, 3.1, 0, 0, 3])\n",
        "\n",
        "# Chuyển đổi dữ liệu của Angelina Jolie thành DataFrame (với kiểu Vector cho cột 'features')\n",
        "def create_features_vector(features):\n",
        "    return Vectors.dense(features)\n",
        "\n",
        "# Chuyển dữ liệu của Angelina Jolie thành DataFrame\n",
        "angelina_df = spark.createDataFrame([(create_features_vector(angelina_jolie_features.tolist()),)], [\"features\"])\n",
        "\n",
        "# Dự đoán\n",
        "angelina_prediction = model.transform(angelina_df).select(\"prediction\").collect()[0][0]\n",
        "print(f\"Angelina Jolie - Prediction: {'Heart Disease' if angelina_prediction == 1.0 else 'No Heart Disease'}\")\n",
        "\n",
        "# Dừng Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUjXG8uod9Hc",
        "outputId": "d444fa7c-3042-4a3c-c85d-3b525b962569"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 52.17%\n",
            "Angelina Jolie - Prediction: No Heart Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier dự đoán bệnh tim cho Angelina Jolie\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, FloatType\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Khởi tạo Spark session\n",
        "spark = SparkSession.builder.appName(\"DecisionTreeClassifier\").getOrCreate()\n",
        "\n",
        "# Hàm tạo dữ liệu ngẫu nhiên với 13 đặc trưng\n",
        "def generate_data(num_samples):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        label = float(np.random.choice([0.0, 1.0]))  # Chuyển đổi thành float\n",
        "        features = [float(np.random.uniform(1.0, 20.0)) for _ in range(13)]\n",
        "        data.append((label,) + tuple(features))\n",
        "    return data\n",
        "\n",
        "# Sinh 50 dòng dữ liệu\n",
        "data = generate_data(50)\n",
        "\n",
        "# Định nghĩa schema cho DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"label\", FloatType(), False),\n",
        "    *[StructField(f\"feature{i}\", FloatType(), False) for i in range(1, 14)]  # 13 đặc trưng\n",
        "])\n",
        "\n",
        "# Tạo DataFrame từ dữ liệu\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Chuyển đổi các cột đặc trưng thành một vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"feature{i}\" for i in range(1, 14)],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "df = assembler.transform(df)\n",
        "df = df.select(\"label\", \"features\")\n",
        "\n",
        "# Tạo mô hình DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "(training_data, test_data) = df.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "model = dt.fit(training_data)\n",
        "\n",
        "# Dự đoán trên tập kiểm tra\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Đánh giá mô hình\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Dự đoán cho một bệnh nhân cụ thể\n",
        "# Ví dụ về đặc trưng của bệnh nhân với 13 đặc trưng\n",
        "angelina_features = [53.0, 1.0, 0.0, 140.0, 203.0, 1.0, 0.0, 155.0, 1.0, 3.1, 0.0, 0.0, 3.0]\n",
        "\n",
        "# Chuyển đổi đặc trưng thành DataFrame\n",
        "angelina_df = spark.createDataFrame(\n",
        "    [tuple(angelina_features)],\n",
        "    schema=StructType([StructField(f\"feature{i}\", FloatType(), False) for i in range(1, 14)])\n",
        ")\n",
        "\n",
        "# Chuyển đổi các cột đặc trưng thành một vector\n",
        "angelina_df = assembler.transform(angelina_df)\n",
        "\n",
        "# Dự đoán\n",
        "angelina_prediction = model.transform(angelina_df).select(\"prediction\").collect()[0][0]\n",
        "print(f\"Angelina Jolie - Prediction: {'Heart Disease' if angelina_prediction == 1.0 else 'No Heart Disease'}\")\n",
        "\n",
        "# Dừng Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx6iOE-ljf0l",
        "outputId": "b0c66dc5-8f09-425e-f8dc-376f6ae90c5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 62.50%\n",
            "Angelina Jolie - Prediction: No Heart Disease\n"
          ]
        }
      ]
    }
  ]
}